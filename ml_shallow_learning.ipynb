{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow Machine Learning Introduction\n",
    "- **s**ci**k**it-**learn** (a.k.a. sklearn)\n",
    "- https://scikit-learn.org\n",
    "- installation: https://scikit-learn.org/stable/install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catagories\n",
    "\n",
    "| <font color='dodgerblue'>Regression</font> | <font color='dodgerblue'>Classification</font> | <font color='dodgerblue'>Clustering</font> | <font color='dodgerblue'>Dimension Reduction</font>|\n",
    "| :-: | :-: | :-: | :-: |\n",
    "| **Linear** | Logistic Regression | K-means | Principle Component Analysis |\n",
    "| Polynomial | Support Vector Machine | Mean-Shift | Linear Discriminant Analysis |\n",
    "| StepWise | Naive Bayes | DBScan | Gernalized Discriminant Analysis |\n",
    "| Ridge | Nearest Neighbor | Agglomerative Hierachcial | Autoencoder |\n",
    "| Lasso | Decision Tree | Spectral Clustering | Non-Negative Matrix Factorization |\n",
    "| ElasticNet | Random Forest | Gaussian Mixture | UMAP |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><center><img alt=\"Classification\" width=\"600\" src=\"00_images/31_machine_learning/shallow_learning_depictions.jpg\" align=\"center\" hspace=\"10px\" vspace=\"0px\"></center></p>\n",
    "\n",
    "**Image Source**: de Oliveira, E.C.L., da Costa, K.S., Taube, P.S., Lima, A.H. and Junior, C.D.S.D.S., 2022. Biological Membrane-Penetrating Peptides: Computational Prediction and Applications. Frontiers in Cellular and Infection Microbiology, 12, p.838259. (https://doi.org/10.3389/fcimb.2022.838259)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"></hr>\n",
    "\n",
    "## Linear Regression Refresher\n",
    "\n",
    "**Idea**: <font color='dodgerblue'>Optimize the orientation of a line</font> that **best fits** **coupled/correlated parameters** \n",
    "- **1 dependent** and **1 independent**** variable: $y = m*x + b$\n",
    "- optimize the **slope** and **y-intercept**\n",
    "- a simple, but prominent technique in ML\n",
    "- used frequently in supervised learning\n",
    "\n",
    "**Example Data**\n",
    "- vaccination effectiveness and dosage\n",
    "- $\\text{CO}_2$ emissions and engine size\n",
    "- life expectancy and vacinnation coverage\n",
    "- GPA and course attendance\n",
    "\n",
    "\n",
    "Additional Info: https://en.wikipedia.org/wiki/Linear_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning by example\n",
    "\n",
    "**Example data**: housing prices across the United States\n",
    "\n",
    "source: https://github.com/whoparthgarg/House-Price-Prediction (and https://www.kaggle.com/vedavyasv/usa-housing)\n",
    "\n",
    "- **Avg. Area Income**: Average income of the city's residents where the house is located in\n",
    "- **Avg. Area House Age**: Average age of houses within the same city\n",
    "- **Avg. Area Number of Rooms**: Avgerage number of rooms for houses within the same city\n",
    "- **Avg. Area Number of Bedrooms**: Average number of bedrooms for houses within the same city\n",
    "- **Area Population**: Population of the city where the house is located in\n",
    "- **Price**: Price of the house\n",
    "- **Address**: Address for the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset (**usa_housing.csv**) can be downloaded from the git repository: https://github.com/karlkirschner/Scientific_Programming_Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -2 usa_housing.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the headers since the are very long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('usa_housing.csv', header=1,\n",
    "                      names=['income', 'age', 'rooms', 'bedrooms', 'population', 'price', 'address'])\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observables - a.k.a. \"Features\"\n",
    "\n",
    "(Definitions of words used in ML.)\n",
    "\n",
    "What **features** do we want the machine **to learn from** for **making a prediction** of a **target observable**?\n",
    "\n",
    "- <font color='dodgerblue'>features</font>: independent variables (`income`, `age`, `rooms`, `bedrooms`, `population`)\n",
    "- <font color='dodgerblue'>target observable</font>: dependent variable (`price`)\n",
    "\n",
    "\n",
    "Coding-wise, we can define the features like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['income', 'age', 'rooms', 'bedrooms', 'population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the data\n",
    "Let's plot the features versus price to see what it might look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11, 8))\n",
    "\n",
    "fig.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "for count, feature in enumerate(feature_list):\n",
    "    ax = fig.add_subplot(3, 2, count+1)  # first position can not be zero\n",
    "\n",
    "    ax.set_xlabel(xlabel=feature)\n",
    "    ax.set_ylabel(ylabel='price')\n",
    "\n",
    "    ax.scatter(housing[feature], housing['price'], color='dodgerblue', s=10, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"></hr>\n",
    "\n",
    "## Linear Regression on a Single Feature (i.e., one-dimensional)\n",
    "\n",
    "The **simplest scenario** is to focus on **1 feature** (e.g., `rooms`) and see if we can create a model for predicting a **house price** (i.e., `price`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = housing['rooms'].values\n",
    "target = housing['price'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing\n",
    "\n",
    "- Good **data scholarship** means we need to **split our data** into a **training** and **test** sets. We do this by using the following scikit-learn funtion:\n",
    "\n",
    "`train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)`\n",
    "\n",
    "- Returns: a list containing train-test split of the data input.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train, feature_test, target_train, target_test = train_test_split(feature, target,\n",
    "                                                                          test_size=0.25, train_size=0.75,\n",
    "                                                                          random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check the algorithm - we should have 25% of the data being researved for the future testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Length of the training data: {len(target_train)}')\n",
    "print(f'Length of the test data: {len(target_test)}')\n",
    "\n",
    "print(f'Fraction of data used for the test data set: '\n",
    "      f'{len(target_test) / (len(target_train) + len(target_test)) :0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(feature_train, target_train, s=10, label='Training Data')\n",
    "plt.scatter(feature_test, target_test, s=8, label='Test Data')\n",
    "\n",
    "plt.xlabel(xlabel='# of Rooms')\n",
    "plt.ylabel(ylabel='Price')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape the data\n",
    "- scikit-learn's <font color='dodgerblue'>LinearRegression</font> requires the data to have a certain <font color='dodgerblue'>NumPy array shape</font>\n",
    "- **Already Done**: the `target_train` and `target_test` are both already in their correct shape\n",
    "- **Need to Do**:  reshape `feature_train` and `feature_test` (becuase it is a 1 feature)\n",
    "\n",
    "Feature Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(feature_train)\n",
    "display(feature_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(feature_test)\n",
    "display(feature_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have **one feature** (i.e., one column; number of rooms), the feature arrays need **reshaping to contain nested lists**.\n",
    "\n",
    "**Note:** If we do not reshape the data, then in the next step (i.e., `model = reg.fit(X=features_train, y=target_train)`) we would obtain the following error:\n",
    "\n",
    "`ValueError: Expected 2D array, got 1D array instead:\n",
    "array=[7.76350224 6.67325638 6.39398078 ... 6.11019169 7.04733826 5.35511362].\n",
    "Reshape your data using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.`\n",
    "\n",
    "Numpy's reshape function: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html\n",
    "- One shape dimension can be -1\n",
    "    - Then, the value is taken as the array length.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(feature_train)\n",
    "display(feature_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = np.reshape(feature_train, (-1, 1))\n",
    "features_test = np.reshape(feature_test, (-1, 1))\n",
    "\n",
    "display(feature_train)\n",
    "display(feature_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squared Linear Regression\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "- `sklearn.linear_model.LinearRegression(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)`\n",
    "\n",
    "We will train in two steps\n",
    "1. Define our **callable model**\n",
    "    - linear regression\n",
    "    - fit the y-intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Have the model **learn** from our data (i.e., optimize for a best fit)\n",
    "     - This is the creation of a **model** that represents our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = reg.fit(X=feature_train, y=target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(model))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions using your model\n",
    "\n",
    "- `predict`: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict\n",
    "    - **Args**: np.ndarray of feature(s)\n",
    "    - **Return**: predicted target value\n",
    "\n",
    "**Create a new/independent/unknown house**:\n",
    "- Known feature: <font color='dodgerblue'>5 rooms</font>\n",
    "- Predict target: <font color='dodgerblue'>Cost</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_house_feature = np.array([ [5] ])\n",
    "\n",
    "display(new_house_feature)\n",
    "display(new_house_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X=new_house_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Thus, the house with 5 rooms is predicted to cost ca. {model.predict(X=new_house_feature)[0]:0.1e} dollars.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate if we had 2 new houses:\n",
    "- 5 rooms\n",
    "- 2 rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_houses_feature = np.array([ [5], [2] ])\n",
    "display(new_houses_feature)\n",
    "display(new_houses_feature.shape)\n",
    "\n",
    "model.predict(X=new_houses_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''Thus, the houses with 5 and 2 rooms are predicted to cost ca.\n",
    "      $ {model.predict(X=new_houses_feature)[0]:0.1e} and\n",
    "      $ {model.predict(X=new_houses_feature)[1]:0.1e}, respectively.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the fit using the Coefficient of Determination ($R^2$)  - goodness-of-fit\n",
    "- https://en.wikipedia.org/wiki/Coefficient_of_determination\n",
    "\n",
    "Two ways to obtain this value:\n",
    "1. `score`\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score\n",
    "    - `score(X, y, sample_weight=None)`\n",
    "    - `sample_weight`: setting the relative importance of the data\n",
    "\n",
    "\n",
    "2. `r2_score`\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score\n",
    "    - `r2_score(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average', force_finite=True)`\n",
    "    - `force_finite`: use when y_true is constant\n",
    "\n",
    "- Score = 1: **Best possible model**\n",
    "    \n",
    "- Score = 0: **Poor model**\n",
    "\n",
    "- Score > 1 or < 0: **Wrong model** (or **wrong constraints applied**)\n",
    "\n",
    "Using the housing **test data** set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(features_test.shape)\n",
    "\n",
    "predict = model.predict(X=features_test)\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X=features_test, y=target_test, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `r2_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=target_test, y_pred=predict, multioutput='uniform_average', sample_weight=None, force_finite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlay the scattered data with the model's prediction\n",
    "- recall that the model is a **linear regression** - straight line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(features_test, target_test, s=10, alpha=0.5, label='raw test data')\n",
    "plt.plot(features_test, predict, color='black', linewidth=5, linestyle='solid', label='Linear Reg. Pred.')\n",
    "\n",
    "plt.xlabel(xlabel='# of Rooms')\n",
    "plt.ylabel(ylabel='Price')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polynomial `coefficients` (i.e. `m`) and `y-intercept` of the resulting fitted line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Coefficients: {model.coef_}')\n",
    "print(f'y-intercept: {model.intercept_}\\n')\n",
    "\n",
    "print(f'''Linear regression line:\n",
    "      y(x) = price(room) = {model.coef_[0]:0.2e}x + {model.intercept_:0.2e}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proof-of-concept\n",
    "\n",
    "- using the **line equation**, our optimized `coefficients` and `y-intercept`, we can predict the price.\n",
    "\n",
    "First, recall from above that this was done using the `predict` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X=np.array([ [5] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using an optimized straight line equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = (model.coef_[0] * 5) + model.intercept_\n",
    "f'{price}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"></hr>\n",
    "\n",
    "## Create a Model from Two Features\n",
    "\n",
    "The equation that defines a line that has two \"features\" (i.e., two independent variables) is \n",
    "\n",
    "$y = m_1*x_1 + m_2*x_2 + b$\n",
    "\n",
    "- $x_1$ and $x_2$ = data for the two features\n",
    "- $m_1$ and $m_2$ = the coefficients\n",
    "- $b$ = y-intercept\n",
    "\n",
    "\n",
    "- Extend this to `n` features (i.e., in multiple-dimensional space).\n",
    "\n",
    "- Let's generate a model that uses 5 features:\n",
    "    - 'income', 'age', 'rooms', 'bedrooms', and 'population'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_features = ['age', 'rooms']\n",
    "\n",
    "display(two_features)\n",
    "display(housing[two_features].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice**: since there are more than **1 features** (i.e., 2 Pandas DataFrame columns), we can pass the **DataFrame directly to `train_test_split`** without reshaping them (unlike the above example using 1 feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(housing[two_features], target,\n",
    "                                                                            test_size=0.25, train_size=0.75,\n",
    "                                                                            random_state=1)\n",
    "\n",
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = reg.fit(X=features_train, y=target_train)\n",
    "\n",
    "model.score(X=features_test, y=target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X=features_test)\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a plot function that allows us to visualize multiple price vs. features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(feature_list: list,\n",
    "                  target: np.ndarray,\n",
    "                  feature_df: pd.DataFrame,\n",
    "                  predict: np.ndarray=None):\n",
    "    ''' Create a plot with multiple subplots displayed in two columns.\n",
    "    \n",
    "        Args\n",
    "            feature_list: y-axis features to be extracted from feature_df (i.e. column names)\n",
    "            target: x-axis data\n",
    "            feature_df: y-axis data\n",
    "            predict: predicted values based on machine learning\n",
    "        Returns\n",
    "            plot\n",
    "        \n",
    "        Library dependencies\n",
    "            matplotlib\n",
    "            numpy\n",
    "            pandas\n",
    "    '''\n",
    "    if not isinstance(feature_list, list):\n",
    "        raise TypeError('Input features are not given as a list.')\n",
    "    elif not isinstance(target, np.ndarray):\n",
    "        raise TypeError('Target values are not given as a NumPy array.')\n",
    "    elif not isinstance(feature_df, pd.DataFrame):\n",
    "        raise TypeError('feature_df is not given as a Pandas dataframe.')\n",
    "    elif not isinstance(predict, np.ndarray):\n",
    "        raise TypeError('predict is not given as a NumPy array.')\n",
    "    else:  \n",
    "\n",
    "        number_of_rows = int(np.ceil(len(feature_list)/2))  # number of rows for a 2 column plot\n",
    "\n",
    "        fig = plt.figure(figsize=(11, 3*number_of_rows))    # same height subplots regardless of rows\n",
    "\n",
    "        fig.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "        for count, feature in enumerate(feature_list):    \n",
    "            ax = fig.add_subplot(number_of_rows, 2, count+1)  # first position can not be zero\n",
    "\n",
    "            ax.set_xlabel(xlabel=feature)\n",
    "            ax.set_ylabel(ylabel='price')\n",
    "\n",
    "            ax.scatter(feature_df[feature], target, color='dodgerblue', s=20, alpha=0.3, label='known')\n",
    "\n",
    "            if predict is not None:\n",
    "                ax.scatter(feature_df[feature], predict, color='orange', s=10, alpha=0.5, linestyle='solid', label='prediction')\n",
    "            \n",
    "            ax.legend(loc='best')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(feature_list=two_features, feature_df=features_test, target=target_test, predict=predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What would the resulting two-feature linear equation look like, for one of the input houses?\n",
    "\n",
    "$y = (m_1*x_1) + (m_2*x_2) + (b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Coefficients: {model.coef_}')\n",
    "print()\n",
    "print(f'y-intercept: {model.intercept_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'y = ({model.coef_[0]:0.2e} * x) \\n'\\\n",
    "      f'  + ({model.coef_[1]:0.2e} * x) \\n'\\\n",
    "      f'  + {model.intercept_:0.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply it to an individual house (i.e., the first data entry) to see how it repoduces the actual target value.\n",
    "\n",
    "Use Pandas `loc[[]]` to isolate a row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.loc[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we can use Pandas `loc[[ , ]]` to isolate rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(housing.loc[[0], ['age', 'rooms', 'price']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our **ML model**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = model.predict(X=housing.loc[[0], ['age', 'rooms']])\n",
    "\n",
    "f'{price[0]:0.2e}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, using the **equation for a line**\n",
    "\n",
    "$y = (m_1*x_1) + (m_2*x_2) + (b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'y = ({model.coef_[0]:0.2e} * {float(housing[\"age\"].iloc[0]):0.2e})'\\\n",
    "      f' + ({model.coef_[1]:0.2e} * {float(housing[\"rooms\"].iloc[0]):0.2e})'\\\n",
    "      f' + {model.intercept_:0.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_price = (model.coef_[0] * float(housing[\"age\"].iloc[0]))     \\\n",
    "                + (model.coef_[1] * float(housing[\"rooms\"].iloc[0]))        \\\n",
    "                + model.intercept_\n",
    "\n",
    "f'{predicted_price:0.2e}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_price = housing[\"price\"].iloc[0]\n",
    "\n",
    "print(f'The listed price in the dataset is: {actual_price:0.2e}, '\\\n",
    "      f'a difference of {actual_price-predicted_price:0.2e}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sidenote: plot the line corresponding to each subfeature\n",
    "\n",
    "1. Create a straight line for plotting\n",
    "2. Scatter plot the data and overlay with the straight lines\n",
    "3. Do this in a loop that cycles over the features\n",
    "\n",
    "Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "for observable in two_features:\n",
    "    observable_line = (model.coef_[0] * features_test[observable])\n",
    "    \n",
    "    plt.scatter(features_test[observable], target_test, s=20, alpha=0.5)\n",
    "    plt.plot(features_test[observable], observable_line, linewidth=10, alpha=0.5, linestyle='solid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"></hr>\n",
    "\n",
    "### Model from five features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_features = ['income', 'age', 'rooms', 'bedrooms', 'population']\n",
    "\n",
    "display(housing[five_features])\n",
    "display(housing[five_features].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(housing[five_features], target,\n",
    "                                                                            test_size=0.25, train_size=0.75,\n",
    "                                                                            random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = reg.fit(X=features_train, y=target_train)\n",
    "\n",
    "model.score(X=features_test, y=target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X=features_test)\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how well the ML'ed predicted values in comparison to the original `test` input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(feature_list=five_features, feature_df=features_test, target=target_test, predict=predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply it to an individual house (i.e., the first data entry) to see how it repoduces the actual target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.loc[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our **ML model**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = model.predict(X=housing.loc[[0], five_features])\n",
    "\n",
    "f'{price[0]:0.3e}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, using the **equation for a line**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = (m_1*x_1) + (m_2*x_2) + (m_3*x_3) + (m_4*x_4) + (m_5*x_5) + (b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''  y = ({model.coef_[0]:0.2e} * {float(housing[\"income\"].iloc[0]):0.2e})\n",
    "    + ({model.coef_[1]:0.2e} * {float(housing[\"age\"].iloc[0]):0.2e})\n",
    "    + ({model.coef_[2]:0.2e} * {float(housing[\"rooms\"].iloc[0]):0.2e})\n",
    "    + ({model.coef_[3]:0.2e} * {float(housing[\"bedrooms\"].iloc[0]):0.2e})\n",
    "    + ({model.coef_[4]:0.2e} * {float(housing[\"population\"].iloc[0]):0.2e})\n",
    "    + {model.intercept_:0.2e}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = (model.coef_[0] * float(housing[\"income\"].iloc[0]))     \\\n",
    "      + (model.coef_[1] * float(housing[\"age\"].iloc[0]))        \\\n",
    "      + (model.coef_[2] * float(housing[\"rooms\"].iloc[0]))      \\\n",
    "      + (model.coef_[3] * float(housing[\"bedrooms\"].iloc[0]))   \\\n",
    "      + (model.coef_[4] * float(housing[\"population\"].iloc[0])) \\\n",
    "      + model.intercept_\n",
    "\n",
    "f'{price:0.3e}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see very good agreement between the model predicted value and the target `$ 1.506e+06` value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"></hr>\n",
    "\n",
    "#### How do you run the model for a new house?\n",
    "\n",
    "1. Create a new dataframe that provides the house's features\n",
    "2. Use `predict` to generate a predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_house_features = pd.DataFrame(np.array([ [8.00e4, 6.5, 7.0, 4.0, 40.0e3 ] ]),\n",
    "                                  columns=five_features)\n",
    "\n",
    "display(new_house_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_house_price = model.predict(X=new_house_features)\n",
    "new_house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(new_house_features)\n",
    "\n",
    "print(f'The cost of the above house is predicted to be: ${float(new_house_price[0]):0.3e}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"></hr>\n",
    "\n",
    "## Clustering\n",
    "\n",
    "### Why Cluster?\n",
    "**<font color='dodgerblue'>One clusters data to discover inherent structures and patterns within a dataset.</font>**\n",
    "\n",
    "- **Exploratory Data Analysis**: first step in understanding a new dataset\n",
    "    - Identify natural divisions, outliers, or dominant characteristics\n",
    "    - helps in forming hypotheses for further analysis\n",
    "\n",
    "- **Simplification and Summarization**: focus on the cluster characteristics themselves (not individual data points)\n",
    "    -  more conceptually manageable\n",
    "\n",
    "- **Data Preprocessing and Compression**: dimensionality reduction\n",
    "    - speed up computations\n",
    "    - more conceptually manageable\n",
    "\n",
    "- **Anomaly Detection**: Data points that do not fit well into any cluster, or form very small, isolated clusters, can be identified as anomalies or outliers.\n",
    "    - pollution monitoring\n",
    "    - disease outbreaks\n",
    "    - error detection in experiments\n",
    "\n",
    "- **Feature Engineering**: cluster assignments themselves can be used as new features for supervised learning tasks\n",
    "\n",
    "\n",
    "### Scikit-learn Algorithms\n",
    "- https://scikit-learn.org/1.5/modules/clustering.html\n",
    "\n",
    "**<font color='dodgerblue'>Distances between Points</font>** (the core techniques)\n",
    "\n",
    "- **K-Means** (widely used)\n",
    "    - General-purpose, even cluster size, flat geometry, not too many clusters, inductive\n",
    "\n",
    "- **Mean-shift**\n",
    "    - Many clusters, uneven cluster size, non-flat geometry, inductive\n",
    "    - Distances between points\n",
    "\n",
    "- **Ward hierarchical clustering**\n",
    "    - Many clusters, possibly connectivity constraints, transductive\n",
    "    - Distances between points\n",
    "\n",
    "- **OPTICS**\n",
    "    - Non-flat geometry, uneven cluster sizes, variable cluster density, outlier removal, transductive\n",
    "    - Distances between points\n",
    "\n",
    "- **Bisecting K-Means**\n",
    "    - General-purpose, even cluster size, flat geometry, no empty clusters, inductive, hierarchical\n",
    "    - Distances between points\n",
    "\n",
    "**<font color='dodgerblue'>Distances between nearest points</font>** (more specialized techniques)\n",
    "\n",
    "- **DBSCAN**\n",
    "    - identify clusters as **dense regions of points** in the data space, **separated** by areas of **lower point density** (noise).\n",
    "    - Non-flat geometry, uneven cluster sizes, outlier removal, transductive\n",
    "\n",
    "- **HDBSCAN**\n",
    "    - Non-flat geometry, uneven cluster sizes, outlier removal, transductive, hierarchical, variable cluster density\n",
    "\n",
    "**<font color='dodgerblue'>Graph distance (e.g. nearest-neighbor graph)</font>**\n",
    "\n",
    "- **Affinity propagation**\n",
    "    - Many clusters, uneven cluster size, non-flat geometry, inductive\n",
    "\n",
    "- **Spectral clustering**\n",
    "    - Few clusters, even cluster size, non-flat geometry, transductive\n",
    "\n",
    "**<font color='dodgerblue'>Others</font>**\n",
    "\n",
    "- **Gaussian mixtures**\n",
    "    - Flat geometry, good for density estimation, inductive\n",
    "    - Mahalanobis distances to centers\n",
    "\n",
    "\n",
    "- **BIRCH**\n",
    "    - Large dataset, outlier removal, data reduction, inductive\t\n",
    "    - Euclidean distance between points\n",
    "\n",
    "\n",
    "- **Agglomerative clustering**\n",
    "    - Many clusters, possibly connectivity constraints, non-Euclidean distances, transductive\n",
    "    - Any pairwise distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Scaling data to have the same magnitude\n",
    "\n",
    "Clustering and Dimonsionality reduction often benefit from working on data with similar magnitude.\n",
    "\n",
    "- Scale numerical values: drop the `Address` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.drop('address', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `StandardScaler`\n",
    "\n",
    "  $x_{scaled} = \\frac{(x - mean)}{sd}$\n",
    "\n",
    "  where $sd$ is the standard deviation.\n",
    "\n",
    "*We will also import seaborn for easily creating nice plots of the resulting data analysis.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(housing)\n",
    "scaled_features_df = pd.DataFrame(scaled_features, columns=housing.columns)\n",
    "\n",
    "scaled_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovering the scaled data\n",
    "\n",
    "Original, unscaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_data = scaler.inverse_transform(scaled_features)\n",
    "recovered_df = pd.DataFrame(recovered_data, columns=housing.columns)\n",
    "recovered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now back to clustering...\n",
    "\n",
    "#### kmeans\n",
    "\n",
    "`sklearn.cluster.k_means(X, n_clusters, *, sample_weight=None, init='k-means++', n_init='auto', max_iter=300, verbose=False, tol=0.0001, random_state=None, copy_x=True, algorithm='lloyd', return_n_iter=False)`\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.cluster.k_means.html\n",
    "- `X` needs to have data passed in a **2-dimensional container** (e.g., np.ndarray[[]]: `X=np.array([[1, 2], [1, 4], [1, 0]`)\n",
    "\n",
    "**Returns**:\n",
    "- <font color='dodgerblue'>centroids</font>: cluster centers (i.e., coordinates)\n",
    "- <font color='dodgerblue'>labels</font>: the centroid index that each data point belongs to\n",
    "- <font color='dodgerblue'>inertia</font>: a metric for how well the data points belong to the clusters\n",
    "    - \"sum of squared distances to the closest centroid for all observations in the training set\"\n",
    "    - <font color='dodgerblue'>It quantifies how \"tight\" or \"compact\" the clusters are.</font> - a lower value indicates tighter clusters.\n",
    "    <!-- - Practical usage - in conjunction with the Elbow Method to help determine a reasonable number of clusters (K) by observing the point of diminishing returns in inertia reduction. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import k_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we can access specific columns in the DataFrame via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features_df[['income', 'rooms', 'price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Example 1**: how it **fails** when not including the properly shaped `X`.\n",
    "\n",
    "- `X` needs to have data passed in a **2-dimensional container** (e.g., np.ndarray[[]]: `X=np.array([[1, 2], [1, 4], [1, 0]`)\n",
    "- housing['income']: 1-dimens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features_df['income'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, labels, inertia = k_means(X=scaled_features_df['income'], n_clusters=3, random_state=0, n_init='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example 2: a properly shaped `X`:\n",
    "- `X=scaled_features_df[['income']]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features_df[['income']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, labels, inertia = k_means(X=scaled_features_df[['income']], n_clusters=3, random_state=0, n_init='auto')\n",
    "\n",
    "display(f'Centroids: {centroids}')\n",
    "display(f'Labels:    {labels}')\n",
    "display(f'Inertia:   {inertia:.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example 3: of a properly shaped `X`:\n",
    "- `X=housing[['income', 'population']]`\n",
    "- Adding complexity now with clustering based on two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_features = ['income', 'population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, labels, inertia = k_means(X=scaled_features_df[cluster_features], n_clusters=2, random_state=0, n_init='auto')\n",
    "\n",
    "display(f'Centroids: {centroids}')\n",
    "display(f'Labels:    {labels}')\n",
    "display(f'Inertia:   {inertia:.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, labels, inertia = k_means(X=scaled_features_df[cluster_features], n_clusters=3, random_state=0, n_init='auto')\n",
    "\n",
    "display(f'Centroids: {centroids}')\n",
    "display(f'Labels:    {labels}')\n",
    "display(f'Inertia:   {inertia:.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Inertia goes down with increasing clusters\n",
    "- always true - more clusters lower inertia (\"tighter\" cluster)\n",
    "- In practice: you need to decide when getting better inertia has little impact (e.g. elbow method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 5))\n",
    "sns.scatterplot(data=scaled_features_df, x='income', y='population', hue=labels)\n",
    "\n",
    "for centroid_centers in centroids:\n",
    "    plt.scatter(x=centroid_centers[0], y=centroid_centers[1],\n",
    "                marker=r\"$\\odot$\", s=150, edgecolor='DodgerBlue', linewidths=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_features = ['bedrooms', 'rooms']\n",
    "\n",
    "inertias_list = []\n",
    "\n",
    "cluster_number = range(1, 15)\n",
    "\n",
    "for i in cluster_number:\n",
    "    centroids, labels, inertia = k_means(X=scaled_features_df[cluster_features], n_clusters=i, random_state=0, n_init='auto')\n",
    "    inertias_list.append(inertia)\n",
    "\n",
    "plt.plot(cluster_number, inertias_list, marker='o')\n",
    "plt.title('Elbow method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay - let's take `n_culster` to be `6` as the approximate elbow bend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, labels, inertia = k_means(X=scaled_features_df[cluster_features], n_clusters=6, random_state=0, n_init='auto')\n",
    "\n",
    "display(f'Centroids: {centroids}')\n",
    "display(f'Labels:    {labels}')\n",
    "display(f'Inertia:   {inertia:.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 5))\n",
    "\n",
    "# sns.scatterplot(data=housing, x='bedrooms', y='rooms', hue=labels)\n",
    "sns.scatterplot(data=scaled_features_df, x='income', y='population', hue=labels)\n",
    "\n",
    "for centroid_centers in centroids:\n",
    "    plt.scatter(x=centroid_centers[0], y=centroid_centers[1],\n",
    "                marker=r\"$\\odot$\", s=150, edgecolor='DodgerBlue', linewidths=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"></hr>\n",
    "\n",
    "## Dimensionality Reduction\n",
    "\n",
    "### Why Reduce a Dataset's Dimensions?\n",
    "\n",
    "- Simplify complex datasets by reducing the number of features (variables) while retaining as much meaningful information as possible\n",
    "- \"Dimensionality reduction is a method for representing a given dataset using a lower number of features (i.e. dimensions) while still capturing the original data’s meaningful properties.\" [1]\n",
    "\n",
    "- helps us **understand** the data better\n",
    "    - **visualization**\n",
    "- **improves machine learning performance**\n",
    "- can help the data analysis by **reducing the original data's noise**\n",
    "\n",
    "### Scikit-learn Algorithms\n",
    "- https://scikit-learn.org/stable/modules/unsupervised_reduction.html\n",
    "\n",
    "- <font color='dodgerblue'>Principal Component Analysis</font> (**PCA**)\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA\n",
    "    - **Reproducible** (deterministic)\n",
    "    - Linear\n",
    "    - **Unsupervised** learning\n",
    "    - Most fundamental approach - good for when data has linear structure\n",
    "\n",
    "<br>\n",
    "\n",
    "- <font color='dodgerblue'>Linear Discriminant Analysis</font> (**LDA**)\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
    "    - **Reproducible** (deterministic)\n",
    "    - Linear \n",
    "    - **supervised** learning\n",
    "    - Very good for class separation - finds dimensions that best discriminate between classes\n",
    "\n",
    "<br>\n",
    "\n",
    "- <font color='dodgerblue'>t-Distributed Stochastic Neighbor Embedding</font> (**t-SNE**)\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE\n",
    "    - **Not reproducible** (non-deterministic; **stochastic**) due to random number usage\n",
    "        - However, setting the **`random_state`** does allow reprodicibility\n",
    "        - Proper usage is doing randomly, **multiple times** and **gather statistics**\n",
    "    - **Non-linear**\n",
    "    - **Unsupervised** learning\n",
    "    - **preserve local data structures** (close points in the high-dimensions are  also close in low-dimensions)\n",
    "\n",
    "\n",
    "**Note**:\n",
    "- `decomposition module`: algorithms dedicated to transforming data by \"decomposing\" it into fundamental components or factors (i.e. PCA) - mostly **linear** in nature\n",
    "- `manifolds module`: algorithms dedicated to discovering **non-linear** structures within high-dimensional data.\n",
    "    - A \"manifold\" is a lower-dimensional space embedded within a higher-dimensional space.\n",
    "\n",
    "**Reference**\n",
    "1. **Source**: https://www.ibm.com/topics/dimensionality-reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "\n",
    "Look for a feature combination (in the reduced dimensions) that best captures the variance of the original features.\n",
    "\n",
    "`decomposition.PCA` - sets up your PCA analysis with how many dimension are wanted\n",
    "\n",
    "`class sklearn.decomposition.PCA(n_components=None, *, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', n_oversamples=10, power_iteration_normalizer='auto', random_state=None)`\n",
    "\n",
    "-`n_components`\n",
    "    - Number of components to keep - how many dimensions is the data reduced to\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fit(X, y=None)`\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pca.fit_transform(scaled_features_df)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_1 = clusters[0:100, 0] # first 100 rows of column 0\n",
    "pca_2 = clusters[0:100, 1] # for column 1\n",
    "pca_3 = clusters[0:100, 2] # for column 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(pca_1, pca_2, c=pca_1, cmap=plt.get_cmap('Dark2', 3), alpha=0.2)\n",
    "plt.xlabel('pc1')\n",
    "plt.ylabel('pc2')\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(pca_1, pca_3, c=pca_1, cmap=plt.get_cmap('Dark2', 3), alpha=0.2)\n",
    "plt.xlabel('pc1')\n",
    "plt.ylabel('pc3')\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(pca_2, pca_3, c=pca_1, cmap=plt.get_cmap('Dark2', 3), alpha=0.2)\n",
    "plt.xlabel('pc2')\n",
    "plt.ylabel('pc3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "fig = ax.scatter(pca_1, pca_2, pca_3, c=pca_3, cmap=plt.get_cmap('Dark2', 3))\n",
    "\n",
    "ax.set_xlabel('pca 1')\n",
    "ax.set_ylabel('pca 2')\n",
    "ax.set_zlabel('pca 3')\n",
    "\n",
    "ax.set_box_aspect(None, zoom=0.9) # Keep original box aspect ratio\n",
    "\n",
    "plt.colorbar(fig, shrink=0.30, location='right', label='PCA 3 Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-SNE\n",
    "\n",
    "- Very sensitive to feature scaling: use sklearn's `StandardScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set the `random_state` for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "tsne_results_2d = tsne.fit_transform(scaled_features_df)\n",
    "\n",
    "pd.DataFrame(tsne_results_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_1 = tsne_results_2d[0:100, 0]\n",
    "tsne_2 = tsne_results_2d[0:100, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "plt.scatter(tsne_1, tsne_2, c=tsne_1, cmap=plt.get_cmap('Dark2', 2), alpha=0.5)\n",
    "\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_3d = TSNE(n_components=3, random_state=42)\n",
    "tsne_results_3d = tsne_3d.fit_transform(scaled_features_df)\n",
    "\n",
    "tsne_3d_1 = tsne_results_3d[0:100, 0]\n",
    "tsne_3d_2 = tsne_results_3d[0:100, 1]\n",
    "tsne_3d_3 = tsne_results_3d[0:100, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter_plot = ax.scatter(tsne_3d_1, tsne_3d_2, tsne_3d_3, c=tsne_3d_3, cmap=plt.get_cmap('plasma', 3), alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.set_zlabel('t-SNE 3')\n",
    "\n",
    "ax.set_box_aspect(None, zoom=0.9) # Keep original box aspect ratio\n",
    "\n",
    "plt.colorbar(scatter_plot, shrink=0.30, location='right', label='t-SNE 3 Value')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
